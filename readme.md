## files

`MLP.ipynb` notebook with experiments

`MLP.py` file were percetron was created, on branhc 2lp there's not generalized for n layers but easier to understand 2lp

`SLP.ipynb`playing with linear sepration


## todo


#### MLP

- [ ]  experiments with

  - [ ]  learing rate
  - [ ]  activation functions
  - [ ]  amount and width of layers

in context of epochs, accuracy and overfitting


- [ ]  plots formatiing, titles etc


#### SLP - opitonal

- [ ]  proper gradient back prop
- [ ]  some experiments with slp/mlp - cannot aproximate quadratic function without non-linear activations
